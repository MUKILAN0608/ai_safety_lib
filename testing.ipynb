{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ebd0041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd221f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d83f219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/Mukil/ai_safety_lib\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.20.0 in .\\.venv\\Lib\\site-packages (from ai-safety-lib==0.2.0) (2.4.2)\n",
      "Requirement already satisfied: pyyaml>=6.0 in .\\.venv\\Lib\\site-packages (from ai-safety-lib==0.2.0) (6.0.3)\n",
      "Building wheels for collected packages: ai-safety-lib\n",
      "  Building editable for ai-safety-lib (pyproject.toml): started\n",
      "  Building editable for ai-safety-lib (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for ai-safety-lib: filename=ai_safety_lib-0.2.0-0.editable-py3-none-any.whl size=7883 sha256=0c57c37f587742289f78f719fa40243b3fb7a3ad964262951aea95c13afdd5ce\n",
      "  Stored in directory: C:\\Users\\Mukil\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-sghha50z\\wheels\\6e\\39\\4a\\9c775ca733893d701b39a9f1e53df68bd1afa1b9312ffff137\n",
      "Successfully built ai-safety-lib\n",
      "Installing collected packages: ai-safety-lib\n",
      "  Attempting uninstall: ai-safety-lib\n",
      "    Found existing installation: ai-safety-lib 0.2.0\n",
      "    Uninstalling ai-safety-lib-0.2.0:\n",
      "      Successfully uninstalled ai-safety-lib-0.2.0\n",
      "Successfully installed ai-safety-lib-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -e .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfffb665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Safety Library loaded\n"
     ]
    }
   ],
   "source": [
    "from ai_safety_lib import SafetyGate\n",
    "print(\"AI Safety Library loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae50e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in .\\.venv\\Lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in .\\.venv\\Lib\\site-packages (from scikit-learn) (2.4.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in .\\.venv\\Lib\\site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in .\\.venv\\Lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in .\\.venv\\Lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9e42cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 2.4.2\n",
      "Scikit-learn: 1.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"Scikit-learn:\", sklearn.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0516a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ea23290",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6fe7821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model trained successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41327a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NORMAL INPUT ===\n",
      "Confidence: 0.8820408955973951\n",
      "Entropy: 0.3628388100635645\n"
     ]
    }
   ],
   "source": [
    "sample = X_test_scaled[0].reshape(1, -1)\n",
    "probs = model.predict_proba(sample)[0]\n",
    "\n",
    "confidence = float(np.max(probs))\n",
    "entropy = float(-np.sum(probs * np.log(probs + 1e-8)))\n",
    "\n",
    "model_output = {\n",
    "    \"confidence\": confidence,\n",
    "    \"entropy\": entropy\n",
    "}\n",
    "\n",
    "print(\"=== NORMAL INPUT ===\")\n",
    "print(\"Confidence:\", confidence)\n",
    "print(\"Entropy:\", entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b40319f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DRIFTED INPUT ===\n",
      "Confidence: 0.9983572360106597\n",
      "Entropy: 0.012173770043666397\n"
     ]
    }
   ],
   "source": [
    "drifted_sample = sample + np.random.normal(0, 1.5, sample.shape)\n",
    "\n",
    "probs_drifted = model.predict_proba(drifted_sample)[0]\n",
    "\n",
    "confidence_drifted = float(np.max(probs_drifted))\n",
    "entropy_drifted = float(-np.sum(probs_drifted * np.log(probs_drifted + 1e-8)))\n",
    "\n",
    "drifted_output = {\n",
    "    \"confidence\": confidence_drifted,\n",
    "    \"entropy\": entropy_drifted\n",
    "}\n",
    "\n",
    "print(\"=== DRIFTED INPUT ===\")\n",
    "print(\"Confidence:\", confidence_drifted)\n",
    "print(\"Entropy:\", entropy_drifted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32c774e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SafetyGate initialized successfully\n"
     ]
    }
   ],
   "source": [
    "from ai_safety_lib import SafetyGate\n",
    "gate = SafetyGate(confidence_threshold=0.6)\n",
    "print(\"SafetyGate initialized successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "959f744c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AI SAFETY LIBRARY DECISION ===\n",
      "Overall Risk: 0.5\n",
      "Risk Level: SafetyLevel.WARNING\n",
      "Should Deploy: False\n",
      "\n",
      "Component Risks: {'confidence': 0.5, 'drift': 1.0}\n"
     ]
    }
   ],
   "source": [
    "gate = SafetyGate(confidence_threshold=0.6)\n",
    "\n",
    "# Format the data for SafetyGate\n",
    "predictions = probs_drifted.tolist()\n",
    "\n",
    "# Convert numpy arrays to dictionary format with feature names\n",
    "feature_names = [f\"feature_{i}\" for i in range(sample.shape[1])]\n",
    "reference_data = {name: [sample[0, i]] for i, name in enumerate(feature_names)}\n",
    "current_data = {name: [drifted_sample[0, i]] for i, name in enumerate(feature_names)}\n",
    "\n",
    "assessment = gate.evaluate(\n",
    "    predictions=predictions,\n",
    "    reference_data=reference_data,\n",
    "    current_data=current_data\n",
    ")\n",
    "\n",
    "print(\"=== AI SAFETY LIBRARY DECISION ===\")\n",
    "print(f\"Overall Risk: {assessment.overall_risk}\")\n",
    "print(f\"Risk Level: {assessment.risk_level}\")\n",
    "print(f\"Should Deploy: {gate.should_deploy(assessment)}\")\n",
    "print(f\"\\nComponent Risks: {assessment.component_risks}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5237c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEMPORAL RISK TREND ===\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "SafetyGate.evaluate() got an unexpected keyword argument 'model_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== TEMPORAL RISK TREND ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     decision = \u001b[43mgate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrifted_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mref_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcurr_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrifted_sample\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m â†’ Risk Score:\u001b[39m\u001b[33m\"\u001b[39m, decision[\u001b[33m\"\u001b[39m\u001b[33mrisk_score\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mTypeError\u001b[39m: SafetyGate.evaluate() got an unexpected keyword argument 'model_output'"
     ]
    }
   ],
   "source": [
    "print(\"=== TEMPORAL RISK TREND ===\")\n",
    "\n",
    "risk_scores = []\n",
    "for i in range(5):\n",
    "    assessment = gate.evaluate(\n",
    "        predictions=predictions,\n",
    "        reference_data=reference_data,\n",
    "        current_data=current_data\n",
    "    )\n",
    "    risk_scores.append(assessment.overall_risk)\n",
    "    print(f\"Iteration {i+1} â†’ Risk Score: {assessment.overall_risk:.4f}, Level: {assessment.risk_level}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb87cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fabaa9",
   "metadata": {},
   "source": [
    "## ðŸ“Š Comprehensive Comparison: With vs Without AI Safety Library\n",
    "\n",
    "This section demonstrates the value of the AI Safety Library by:\n",
    "\n",
    "1. **Generating test samples** with varying levels of data drift\n",
    "2. **Comparing predictions** with and without safety checks\n",
    "3. **Visualizing the differences** in 4 comprehensive charts:\n",
    "   - Model confidence degradation \n",
    "   - Risk score assessment\n",
    "   - Deployment decision comparison\n",
    "   - Safety-based filtering visualization\n",
    "\n",
    "Run the cells below to see how the library protects against deploying unsafe predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9434e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26360100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multiple test samples with varying drift levels\n",
    "print(\"Generating test samples with varying drift levels...\\n\")\n",
    "\n",
    "num_samples = 50\n",
    "drift_levels = np.linspace(0, 3, num_samples)  # From no drift to high drift\n",
    "\n",
    "results_without_library = []\n",
    "results_with_library = []\n",
    "\n",
    "for drift_level in drift_levels:\n",
    "    # Create drifted sample\n",
    "    test_sample = sample + np.random.normal(0, drift_level, sample.shape)\n",
    "    \n",
    "    # Get model predictions WITHOUT safety library\n",
    "    probs_test = model.predict_proba(test_sample)[0]\n",
    "    pred_class = np.argmax(probs_test)\n",
    "    confidence_test = float(np.max(probs_test))\n",
    "    \n",
    "    results_without_library.append({\n",
    "        'drift_level': drift_level,\n",
    "        'confidence': confidence_test,\n",
    "        'prediction': pred_class,\n",
    "        'deployed': True  # Without library, everything gets deployed\n",
    "    })\n",
    "    \n",
    "    # Evaluate WITH safety library\n",
    "    predictions_test = probs_test.tolist()\n",
    "    current_data_test = {name: [test_sample[0, i]] for i, name in enumerate(feature_names)}\n",
    "    \n",
    "    assessment_test = gate.evaluate(\n",
    "        predictions=predictions_test,\n",
    "        reference_data=reference_data,\n",
    "        current_data=current_data_test\n",
    "    )\n",
    "    \n",
    "    should_deploy = gate.should_deploy(assessment_test)\n",
    "    \n",
    "    results_with_library.append({\n",
    "        'drift_level': drift_level,\n",
    "        'confidence': confidence_test,\n",
    "        'prediction': pred_class,\n",
    "        'risk_score': assessment_test.overall_risk,\n",
    "        'risk_level': assessment_test.risk_level.value,\n",
    "        'deployed': should_deploy\n",
    "    })\n",
    "\n",
    "print(f\"Generated {num_samples} test samples\")\n",
    "print(f\"Drift range: {drift_levels[0]:.2f} to {drift_levels[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0b5e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Model Behavior: With vs Without AI Safety Library', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Extract data\n",
    "drift_vals = [r['drift_level'] for r in results_without_library]\n",
    "conf_without = [r['confidence'] for r in results_without_library]\n",
    "conf_with = [r['confidence'] for r in results_with_library]\n",
    "risk_scores = [r['risk_score'] for r in results_with_library]\n",
    "deployed_with = [r['deployed'] for r in results_with_library]\n",
    "\n",
    "# Plot 1: Confidence vs Drift Level\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(drift_vals, conf_without, 'o-', label='Without Safety Library', alpha=0.7, linewidth=2)\n",
    "ax1.axhline(y=0.6, color='orange', linestyle='--', label='Confidence Threshold (0.6)', linewidth=2)\n",
    "ax1.set_xlabel('Drift Level', fontsize=12)\n",
    "ax1.set_ylabel('Model Confidence', fontsize=12)\n",
    "ax1.set_title('Model Confidence Degradation with Drift', fontsize=13, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Risk Score from Safety Library\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(drift_vals, risk_scores, 'o-', color='red', label='Risk Score', alpha=0.7, linewidth=2)\n",
    "ax2.axhline(y=0.5, color='orange', linestyle='--', label='Warning Threshold', linewidth=2)\n",
    "ax2.axhline(y=0.7, color='darkred', linestyle='--', label='Critical Threshold', linewidth=2)\n",
    "ax2.set_xlabel('Drift Level', fontsize=12)\n",
    "ax2.set_ylabel('Risk Score', fontsize=12)\n",
    "ax2.set_title('AI Safety Library Risk Assessment', fontsize=13, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.fill_between(drift_vals, 0, risk_scores, alpha=0.2, color='red')\n",
    "\n",
    "# Plot 3: Deployment Decisions\n",
    "ax3 = axes[1, 0]\n",
    "deployed_count_without = sum([1 for r in results_without_library if r['deployed']])\n",
    "deployed_count_with = sum([1 for r in results_with_library if r['deployed']])\n",
    "blocked_count = num_samples - deployed_count_with\n",
    "\n",
    "categories = ['Without\\nSafety Library', 'With\\nSafety Library']\n",
    "deployed_counts = [deployed_count_without, deployed_count_with]\n",
    "blocked_counts = [0, blocked_count]\n",
    "\n",
    "x_pos = np.arange(len(categories))\n",
    "width = 0.6\n",
    "\n",
    "bars1 = ax3.bar(x_pos, deployed_counts, width, label='Deployed', color='green', alpha=0.7)\n",
    "bars2 = ax3.bar(x_pos, blocked_counts, width, bottom=deployed_counts, label='Blocked', color='red', alpha=0.7)\n",
    "\n",
    "ax3.set_ylabel('Number of Predictions', fontsize=12)\n",
    "ax3.set_title('Deployment Decisions Comparison', fontsize=13, fontweight='bold')\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels(categories, fontsize=11)\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height/2,\n",
    "             f'{int(height)}', ha='center', va='center', fontsize=12, fontweight='bold', color='white')\n",
    "if blocked_count > 0:\n",
    "    for i, bar in enumerate(bars2):\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax3.text(bar.get_x() + bar.get_width()/2., deployed_counts[i] + height/2,\n",
    "                     f'{int(height)}', ha='center', va='center', fontsize=12, fontweight='bold', color='white')\n",
    "\n",
    "# Plot 4: Deployment Status Over Drift\n",
    "ax4 = axes[1, 1]\n",
    "deployed_mask = np.array(deployed_with)\n",
    "blocked_mask = ~deployed_mask\n",
    "\n",
    "if np.any(deployed_mask):\n",
    "    ax4.scatter(np.array(drift_vals)[deployed_mask], np.array(conf_with)[deployed_mask], \n",
    "                c='green', s=100, alpha=0.6, label='Deployed (Safe)', marker='o', edgecolors='darkgreen', linewidth=1.5)\n",
    "if np.any(blocked_mask):\n",
    "    ax4.scatter(np.array(drift_vals)[blocked_mask], np.array(conf_with)[blocked_mask], \n",
    "                c='red', s=100, alpha=0.6, label='Blocked (Unsafe)', marker='x', linewidth=2)\n",
    "\n",
    "ax4.axhline(y=0.6, color='orange', linestyle='--', label='Confidence Threshold', linewidth=2)\n",
    "ax4.set_xlabel('Drift Level', fontsize=12)\n",
    "ax4.set_ylabel('Model Confidence', fontsize=12)\n",
    "ax4.set_title('Safety Library Deployment Decisions', fontsize=13, fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1390adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARISON SUMMARY: WITH vs WITHOUT AI Safety Library\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nðŸ“Š WITHOUT Safety Library:\")\n",
    "print(f\"   âœ“ Predictions Deployed: {deployed_count_without}/{num_samples} (100%)\")\n",
    "print(f\"   âœ— Unsafe Predictions Deployed: Unknown (no safety checks)\")\n",
    "print(f\"   âš ï¸  Risk of deploying degraded predictions: HIGH\")\n",
    "\n",
    "print(\"\\nðŸ›¡ï¸  WITH Safety Library:\")\n",
    "print(f\"   âœ“ Safe Predictions Deployed: {deployed_count_with}/{num_samples} ({100*deployed_count_with/num_samples:.1f}%)\")\n",
    "print(f\"   âœ— Unsafe Predictions Blocked: {blocked_count}/{num_samples} ({100*blocked_count/num_samples:.1f}%)\")\n",
    "print(f\"   âš ï¸  Risk of deploying degraded predictions: LOW\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Key Insights:\")\n",
    "avg_risk_deployed = np.mean([r['risk_score'] for r in results_with_library if r['deployed']])\n",
    "avg_risk_blocked = np.mean([r['risk_score'] for r in results_with_library if not r['deployed']]) if blocked_count > 0 else 0\n",
    "\n",
    "print(f\"   â€¢ Average risk of deployed predictions: {avg_risk_deployed:.4f}\")\n",
    "if blocked_count > 0:\n",
    "    print(f\"   â€¢ Average risk of blocked predictions: {avg_risk_blocked:.4f}\")\n",
    "    print(f\"   â€¢ Safety improvement: {blocked_count} risky predictions prevented\")\n",
    "else:\n",
    "    print(f\"   â€¢ All predictions passed safety checks\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
